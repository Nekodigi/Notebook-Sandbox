{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "forgOfmQeA-l"
      },
      "source": [
        "# Stable Diffusion Textual Inversion - Concept Library navigation and usage\n",
        "\n",
        "Navigate through the [public library of concepts](https://huggingface.co/sd-concepts-library) and use Stable Diffusion with custom concepts. ðŸ¤— Hugging Face [ðŸ§¨ Diffusers library](https://github.com/huggingface/diffusers).\n",
        "\n",
        "![Textual Inversion example](https://textual-inversion.github.io/static/images/editing/colorful_teapot.JPG)\n",
        "_By using just 3-5 images new concepts can be taught to Stable Diffusion and the model personalized on your own images_\n",
        "\n",
        "If you would like to teach Stable Diffusion your own concepts, check out the [training notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/sd_textual_inversion_training.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGO3td9-LZzY"
      },
      "source": [
        "## Initial setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FQOlXb7Pdbj2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.2 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# @title Install the required libs\n",
        "!pip install -qq diffusers==0.4.1 transformers ftfy gradio wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnhKBvKidtxK"
      },
      "outputs": [],
      "source": [
        "# @title Login to the Hugging Face Hub\n",
        "# @markdown If you haven't yet, [you have to first acknowledge and agree to the model LICENSE before using it](https://huggingface.co/CompVis/stable-diffusion-v1-4)\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pytorch-triton==3.0.0 (from versions: 0.0.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pytorch-triton==3.0.0\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torchtriton==2.0.0 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torchtriton==2.0.0\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (2.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.2.0) (3.13.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-triton==3.0.0+901819d2b6\n",
        "!pip install torchtriton==2.0.0+0d7e753227\n",
        "!pip install triton==2.2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uvBezVlgfUuL"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Failed to import transformers.generation.utils because of the following error (look up to see its traceback):\ncannot import name 'get_cuda_stream' from 'triton.runtime.jit' (/usr/local/lib/python3.10/dist-packages/triton/runtime/jit.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py:1390\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[0;32m/usr/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:93\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_accelerate_available():\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maccelerate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AlignDevicesHook, add_hook_to_module\n\u001b[1;32m     95\u001b[0m NEED_SETUP_CACHE_CLASSES_MAPPING \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatic\u001b[39m\u001b[38;5;124m\"\u001b[39m: StaticCache,\n\u001b[1;32m     97\u001b[0m }\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.27.2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maccelerator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Accelerator\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbig_modeling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     cpu_offload,\n\u001b[1;32m      6\u001b[0m     cpu_offload_with_hook,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     load_checkpoint_and_dispatch,\n\u001b[1;32m     12\u001b[0m )\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhooks\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpointing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoaderDispatcher, prepare_data_loader, skip_first_batches\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/checkpointing.py:24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mamp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradScaler\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     25\u001b[0m     MODEL_NAME,\n\u001b[1;32m     26\u001b[0m     OPTIMIZER_NAME,\n\u001b[1;32m     27\u001b[0m     RNG_STATE_NAME,\n\u001b[1;32m     28\u001b[0m     SAFE_MODEL_NAME,\n\u001b[1;32m     29\u001b[0m     SAFE_WEIGHTS_NAME,\n\u001b[1;32m     30\u001b[0m     SAMPLER_NAME,\n\u001b[1;32m     31\u001b[0m     SCALER_NAME,\n\u001b[1;32m     32\u001b[0m     SCHEDULER_NAME,\n\u001b[1;32m     33\u001b[0m     WEIGHTS_NAME,\n\u001b[1;32m     34\u001b[0m     get_pretty_name,\n\u001b[1;32m     35\u001b[0m     is_tpu_available,\n\u001b[1;32m     36\u001b[0m     is_xpu_available,\n\u001b[1;32m     37\u001b[0m     save,\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_tpu_available(check_device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/__init__.py:157\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeepspeed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    149\u001b[0m         DeepSpeedEngineWrapper,\n\u001b[1;32m    150\u001b[0m         DeepSpeedOptimizerWrapper,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    154\u001b[0m         HfDeepSpeedConfig,\n\u001b[1;32m    155\u001b[0m     )\n\u001b[0;32m--> 157\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbnb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m has_4bit_bnb_layers, load_and_quantize_model\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfsdp_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_fsdp_model, load_fsdp_optimizer, save_fsdp_model, save_fsdp_optimizer\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/bnb.py:29\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maccelerate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimports\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     25\u001b[0m     is_4bit_bnb_available,\n\u001b[1;32m     26\u001b[0m     is_8bit_bnb_available,\n\u001b[1;32m     27\u001b[0m )\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbig_modeling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch_model, init_empty_weights\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataclasses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BnbQuantizationConfig\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/big_modeling.py:24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     25\u001b[0m     AlignDevicesHook,\n\u001b[1;32m     26\u001b[0m     CpuOffload,\n\u001b[1;32m     27\u001b[0m     UserCpuOffloadHook,\n\u001b[1;32m     28\u001b[0m     add_hook_to_module,\n\u001b[1;32m     29\u001b[0m     attach_align_device_hook,\n\u001b[1;32m     30\u001b[0m     attach_align_device_hook_on_blocks,\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     33\u001b[0m     OffloadedWeightsLoader,\n\u001b[1;32m     34\u001b[0m     check_device_map,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m     retie_parameters,\n\u001b[1;32m     46\u001b[0m )\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:30\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_non_persistent_buffers\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mother\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m recursive_getattr\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mModelHook\u001b[39;00m:\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/other.py:36\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m id_tensor_storage\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformer_engine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_model\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_torch_version\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/transformer_engine.py:21\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_fp8_available():\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransformer_engine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mte\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_model\u001b[39m(model, to_transformer_engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, _convert_linear\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, _convert_ln\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_engine/pytorch/__init__.py:6\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"Transformer Engine bindings for pyTorch\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LayerNormLinear\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Linear\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_engine/pytorch/module/__init__.py:6\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"Module level PyTorch APIs\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayernorm_linear\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LayerNormLinear\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Linear\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_engine/pytorch/module/layernorm_linear.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cpp_extensions \u001b[38;5;28;01mas\u001b[39;00m tex\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     18\u001b[0m     get_workspace,\n\u001b[1;32m     19\u001b[0m     _prepare_backward,\n\u001b[1;32m     20\u001b[0m     get_ub,\n\u001b[1;32m     21\u001b[0m     TransformerEngineBaseModule,\n\u001b[1;32m     22\u001b[0m     _2X_ACC_FPROP,\n\u001b[1;32m     23\u001b[0m     _2X_ACC_DGRAD,\n\u001b[1;32m     24\u001b[0m     _2X_ACC_WGRAD,\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfp8\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_fp8_te_dtype, FP8GlobalStateManager\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_engine/pytorch/module/base.py:21\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexport\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_in_onnx_export_mode\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfp8\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     22\u001b[0m     get_default_fp8_recipe,\n\u001b[1;32m     23\u001b[0m     get_fp8_te_dtype,\n\u001b[1;32m     24\u001b[0m     FP8GlobalStateManager,\n\u001b[1;32m     25\u001b[0m     amax_and_scale_update,\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m     gather_along_first_dim,\n\u001b[1;32m     29\u001b[0m     is_fp8_activation_recompute_enabled,\n\u001b[1;32m     30\u001b[0m     in_fp8_activation_recompute_phase,\n\u001b[1;32m     31\u001b[0m     get_distributed_world_size,\n\u001b[1;32m     32\u001b[0m )\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_engine/pytorch/fp8.py:17\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_device_compute_capability\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m jit_fuser\n\u001b[1;32m     20\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp8_autocast\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp8_model_init\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_engine/pytorch/jit.py:46\u001b[0m\n\u001b[1;32m     42\u001b[0m         torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_jit_override_can_fuse_on_gpu(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;129;43m@jit_fuser\u001b[39;49m\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mbias_gelu_fused_\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"Bias-GeLU fused\"\"\"\u001b[39;49;00m\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py:1774\u001b[0m, in \u001b[0;36mcompile\u001b[0;34m(model, fullgraph, dynamic, backend, mode, options, disable)\u001b[0m\n\u001b[1;32m   1772\u001b[0m     backend \u001b[38;5;241m=\u001b[39m _TorchCompileWrapper(backend, mode, options, dynamic)\n\u001b[0;32m-> 1774\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnopython\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfullgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m)\u001b[49m(model)\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:691\u001b[0m, in \u001b[0;36moptimize\u001b[0;34m(backend, nopython, guard_export_fn, guard_fail_fn, disable, dynamic)\u001b[0m\n\u001b[1;32m    681\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m optimize_assert(\n\u001b[1;32m    682\u001b[0m         backend,\n\u001b[1;32m    683\u001b[0m         dynamic\u001b[38;5;241m=\u001b[39mdynamic,\n\u001b[1;32m    684\u001b[0m         hooks\u001b[38;5;241m=\u001b[39mhooks,\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _optimize_catch_errors(\n\u001b[1;32m    687\u001b[0m     convert_frame\u001b[38;5;241m.\u001b[39mconvert_frame(backend, hooks\u001b[38;5;241m=\u001b[39mhooks),\n\u001b[1;32m    688\u001b[0m     hooks,\n\u001b[1;32m    689\u001b[0m     backend_ctx_ctor,\n\u001b[1;32m    690\u001b[0m     dynamic\u001b[38;5;241m=\u001b[39mdynamic,\n\u001b[0;32m--> 691\u001b[0m     compiler_config\u001b[38;5;241m=\u001b[39m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_compiler_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(backend, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_compiler_config\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    694\u001b[0m )\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py:1619\u001b[0m, in \u001b[0;36m_TorchCompileInductorWrapper.get_compiler_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_compiler_config\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1619\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inductor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompile_fx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_patched_config_dict\n\u001b[1;32m   1620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_patched_config_dict(config_patches\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig)\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py:49\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m select_decomp_table\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx_passes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjoint_graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m joint_graph_passes\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx_passes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpost_grad\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m post_grad_passes, view_to_reshape\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_inductor/fx_passes/joint_graph.py:12\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpattern_matcher\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     13\u001b[0m     CallFunction,\n\u001b[1;32m     14\u001b[0m     init_once_fakemode,\n\u001b[1;32m     15\u001b[0m     KeywordArg,\n\u001b[1;32m     16\u001b[0m     Match,\n\u001b[1;32m     17\u001b[0m     PatternMatcherPass,\n\u001b[1;32m     18\u001b[0m     register_graph_pattern,\n\u001b[1;32m     19\u001b[0m     stable_topological_sort,\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreplace_random\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m replace_random_passes\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_inductor/pattern_matcher.py:44\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m select_decomp_table\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlowering\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fallback_node_due_to_unsupported_type\n\u001b[1;32m     46\u001b[0m log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_inductor/lowering.py:5145\u001b[0m\n\u001b[1;32m   5143\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m kernel\n\u001b[0;32m-> 5145\u001b[0m \u001b[43mimport_submodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5147\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m quantized_lowerings\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py:1639\u001b[0m, in \u001b[0;36mimport_submodule\u001b[0;34m(mod)\u001b[0m\n\u001b[1;32m   1638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m filename[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1639\u001b[0m     \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfilename\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_inductor/kernel/bmm.py:4\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlowering\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_lowering\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mselect_algorithm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     autotune_select_algorithm,\n\u001b[1;32m      6\u001b[0m     ExternKernelChoice,\n\u001b[1;32m      7\u001b[0m     TritonTemplate,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ceildiv \u001b[38;5;28;01mas\u001b[39;00m cdiv, use_aten_gemm_kernels, use_triton_template\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_inductor/select_algorithm.py:24\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcodegen\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChoiceCaller, IndentedBuffer, KernelTemplate\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcodegen\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda_kernel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CUDATemplateCaller\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcodegen\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtriton\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m texpr, TritonKernel, TritonPrinter, TritonScheduling\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_inductor/codegen/cuda/cuda_kernel.py:12\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IndentedBuffer, Kernel, OpOverrides\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcpp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CppPrinter, DTYPE_TO_CPP\n\u001b[1;32m     14\u001b[0m log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_inductor/codegen/cpp.py:23\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m codecache, config, ir, metrics\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcodegen\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrapper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WrapperCodeGen\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimize_indexing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m range_expressable_in_32_bits\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_inductor/codegen/wrapper.py:24\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mir\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ComputedBuffer, InputBuffer\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtriton_heuristics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m grid \u001b[38;5;28;01mas\u001b[39;00m default_grid\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     26\u001b[0m     cache_on_self,\n\u001b[1;32m     27\u001b[0m     get_benchmark_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     sympy_str,\n\u001b[1;32m     31\u001b[0m )\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_inductor/triton_heuristics.py:52\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_triton():\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtriton\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mruntime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_cuda_stream\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_cuda_stream' from 'triton.runtime.jit' (/usr/local/lib/python3.10/dist-packages/triton/runtime/jit.py)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwget\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiffusers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StableDiffusionPipeline\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HfApi\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CLIPTextModel, CLIPTokenizer\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/__init__.py:32\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     get_constant_schedule,\n\u001b[1;32m     24\u001b[0m     get_constant_schedule_with_warmup,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     get_scheduler,\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DiffusionPipeline\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipelines\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DDIMPipeline, DDPMPipeline, KarrasVePipeline, LDMPipeline, PNDMPipeline, ScoreSdeVePipeline\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschedulers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     34\u001b[0m     DDIMScheduler,\n\u001b[1;32m     35\u001b[0m     DDPMScheduler,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     ScoreSdeVeScheduler,\n\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EMAModel\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/pipelines/__init__.py:15\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdummy_pt_objects\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa F403\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available() \u001b[38;5;129;01mand\u001b[39;00m is_transformers_available():\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlatent_diffusion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LDMTextToImagePipeline\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstable_diffusion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     17\u001b[0m         StableDiffusionImg2ImgPipeline,\n\u001b[1;32m     18\u001b[0m         StableDiffusionInpaintPipeline,\n\u001b[1;32m     19\u001b[0m         StableDiffusionPipeline,\n\u001b[1;32m     20\u001b[0m     )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_transformers_available() \u001b[38;5;129;01mand\u001b[39;00m is_onnx_available():\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/pipelines/latent_diffusion/__init__.py:6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_transformers_available\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_transformers_available():\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline_latent_diffusion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LDMBertModel, LDMTextToImagePipeline\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/pipelines/latent_diffusion/pipeline_latent_diffusion.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_outputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModelOutput\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenization_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedTokenizer\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:44\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic_module_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m custom_object_save\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GenerationConfig, GenerationMixin\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeftAdapterMixin, deepspeed_config, is_deepspeed_zero3_enabled\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     Conv1D,\n\u001b[1;32m     48\u001b[0m     apply_chunking_to_forward,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m     prune_linear_layer,\n\u001b[1;32m     55\u001b[0m )\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1075\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py:1380\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1378\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1380\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1381\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1382\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py:1392\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1392\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1393\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1394\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1395\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.generation.utils because of the following error (look up to see its traceback):\ncannot import name 'get_cuda_stream' from 'triton.runtime.jit' (/usr/local/lib/python3.10/dist-packages/triton/runtime/jit.py)"
          ]
        }
      ],
      "source": [
        "# @title Prepare the Concepts Library to be used\n",
        "\n",
        "import requests\n",
        "import os\n",
        "import gradio as gr\n",
        "import wget\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from huggingface_hub import HfApi\n",
        "from transformers import CLIPTextModel, CLIPTokenizer\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "api = HfApi()\n",
        "models_list = api.list_models(author=\"sd-concepts-library\")\n",
        "models = []\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    \"CompVis/stable-diffusion-v1-4\", revision=\"fp16\", torch_dtype=torch.float16\n",
        ").to(\"cuda\")\n",
        "\n",
        "\n",
        "def load_learned_embed_in_clip(\n",
        "    learned_embeds_path, text_encoder, tokenizer, token=None\n",
        "):\n",
        "    loaded_learned_embeds = torch.load(learned_embeds_path, map_location=\"cpu\")\n",
        "\n",
        "    # separate token and the embeds\n",
        "    trained_token = list(loaded_learned_embeds.keys())[0]\n",
        "    embeds = loaded_learned_embeds[trained_token]\n",
        "\n",
        "    # cast to dtype of text_encoder\n",
        "    dtype = text_encoder.get_input_embeddings().weight.dtype\n",
        "    embeds.to(dtype)\n",
        "\n",
        "    # add the token in tokenizer\n",
        "    token = token if token is not None else trained_token\n",
        "    num_added_tokens = tokenizer.add_tokens(token)\n",
        "    i = 1\n",
        "    while num_added_tokens == 0:\n",
        "        print(f\"The tokenizer already contains the token {token}.\")\n",
        "        token = f\"{token[:-1]}-{i}>\"\n",
        "        print(f\"Attempting to add the token {token}.\")\n",
        "        num_added_tokens = tokenizer.add_tokens(token)\n",
        "        i += 1\n",
        "\n",
        "    # resize the token embeddings\n",
        "    text_encoder.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "    # get the id for the token and assign the embeds\n",
        "    token_id = tokenizer.convert_tokens_to_ids(token)\n",
        "    text_encoder.get_input_embeddings().weight.data[token_id] = embeds\n",
        "    return token\n",
        "\n",
        "\n",
        "print(\"Setting up the public library\")\n",
        "for model in tqdm(models_list):\n",
        "    model_content = {}\n",
        "    model_id = model.modelId\n",
        "    model_content[\"id\"] = model_id\n",
        "    embeds_url = f\"https://huggingface.co/{model_id}/resolve/main/learned_embeds.bin\"\n",
        "    os.makedirs(model_id, exist_ok=True)\n",
        "    if not os.path.exists(f\"{model_id}/learned_embeds.bin\"):\n",
        "        try:\n",
        "            wget.download(embeds_url, out=model_id)\n",
        "        except:\n",
        "            continue\n",
        "    token_identifier = (\n",
        "        f\"https://huggingface.co/{model_id}/raw/main/token_identifier.txt\"\n",
        "    )\n",
        "    response = requests.get(token_identifier)\n",
        "    token_name = response.text\n",
        "\n",
        "    concept_type = f\"https://huggingface.co/{model_id}/raw/main/type_of_concept.txt\"\n",
        "    response = requests.get(concept_type)\n",
        "    concept_name = response.text\n",
        "    model_content[\"concept_type\"] = concept_name\n",
        "    images = []\n",
        "    for i in range(4):\n",
        "        url = f\"https://huggingface.co/{model_id}/resolve/main/concept_images/{i}.jpeg\"\n",
        "        image_download = requests.get(url)\n",
        "        url_code = image_download.status_code\n",
        "        if url_code == 200:\n",
        "            file = open(f\"{model_id}/{i}.jpeg\", \"wb\")  ## Creates the file for image\n",
        "            file.write(image_download.content)  ## Saves file content\n",
        "            file.close()\n",
        "            images.append(f\"{model_id}/{i}.jpeg\")\n",
        "    model_content[\"images\"] = images\n",
        "\n",
        "    learned_token = load_learned_embed_in_clip(\n",
        "        f\"{model_id}/learned_embeds.bin\", pipe.text_encoder, pipe.tokenizer, token_name\n",
        "    )\n",
        "    model_content[\"token\"] = learned_token\n",
        "    models.append(model_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOL_FclPLcJw"
      },
      "source": [
        "## Go!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDG37T4ic-KK"
      },
      "outputs": [],
      "source": [
        "# @title Run the app to navigate around [the Library](https://huggingface.co/sd-concepts-library)\n",
        "# @markdown Click the `Running on public URL:` result to run the Gradio app\n",
        "\n",
        "SELECT_LABEL = \"Select concept\"\n",
        "\n",
        "\n",
        "def title_block(title, id):\n",
        "    return gr.Markdown(f\"### [`{title}`](https://huggingface.co/{id})\")\n",
        "\n",
        "\n",
        "def image_block(image_list, concept_type):\n",
        "    return gr.Gallery(label=concept_type, value=image_list, elem_id=\"gallery\").style(\n",
        "        grid=[2], height=\"auto\"\n",
        "    )\n",
        "\n",
        "\n",
        "def checkbox_block():\n",
        "    checkbox = gr.Checkbox(label=SELECT_LABEL).style(container=False)\n",
        "    return checkbox\n",
        "\n",
        "\n",
        "def infer(text):\n",
        "    images_list = pipe(\n",
        "        text, num_images_per_prompt=2, num_inference_steps=50, guidance_scale=7.5\n",
        "    )\n",
        "    output_images = []\n",
        "    for i, image in enumerate(images_list[\"sample\"]):\n",
        "        output_images.append(image)\n",
        "    return output_images\n",
        "\n",
        "\n",
        "css = \"\"\"\n",
        ".gradio-container {font-family: 'IBM Plex Sans', sans-serif}\n",
        "#top_title{margin-bottom: .5em}\n",
        "#top_title h2{margin-bottom: 0; text-align: center}\n",
        "#main_row{flex-wrap: wrap; gap: 1em; max-height: calc(100vh - 16em); overflow-y: scroll; flex-direction: row}\n",
        "@media (min-width: 768px){#main_row > div{flex: 1 1 32%; margin-left: 0 !important}}\n",
        ".gr-prose code::before, .gr-prose code::after {content: \"\" !important}\n",
        "::-webkit-scrollbar {width: 10px}\n",
        "::-webkit-scrollbar-track {background: #f1f1f1}\n",
        "::-webkit-scrollbar-thumb {background: #888}\n",
        "::-webkit-scrollbar-thumb:hover {background: #555}\n",
        ".gr-button {white-space: nowrap}\n",
        ".gr-button:focus {\n",
        "  border-color: rgb(147 197 253 / var(--tw-border-opacity));\n",
        "  outline: none;\n",
        "  box-shadow: var(--tw-ring-offset-shadow), var(--tw-ring-shadow), var(--tw-shadow, 0 0 #0000);\n",
        "  --tw-border-opacity: 1;\n",
        "  --tw-ring-offset-shadow: var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color);\n",
        "  --tw-ring-shadow: var(--tw-ring-inset) 0 0 0 calc(3px var(--tw-ring-offset-width)) var(--tw-ring-color);\n",
        "  --tw-ring-color: rgb(191 219 254 / var(--tw-ring-opacity));\n",
        "  --tw-ring-opacity: .5;\n",
        "}\n",
        "#prompt_input{flex: 1 3 auto}\n",
        "#prompt_area{margin-bottom: .75em}\n",
        "#prompt_area > div:first-child{flex: 1 3 auto}\n",
        "\"\"\"\n",
        "examples = [\n",
        "    \"a <cat-toy> in <madhubani-art> style\",\n",
        "    \"a mecha robot in <line-art> style\",\n",
        "    \"a piano being played by <bonzi>\",\n",
        "]\n",
        "with gr.Blocks(css=css) as demo:\n",
        "    state = gr.Variable({\"selected\": -1})\n",
        "    state = {}\n",
        "\n",
        "    def update_state(i):\n",
        "        global checkbox_states\n",
        "        if checkbox_states[i]:\n",
        "            checkbox_states[i] = False\n",
        "            state[i] = False\n",
        "        else:\n",
        "            state[i] = True\n",
        "            checkbox_states[i] = True\n",
        "\n",
        "    gr.HTML(\n",
        "        \"\"\"\n",
        "  <div style=\"text-align: center; max-width: 720px; margin: 0 auto;\">\n",
        "              <div\n",
        "                style=\"\n",
        "                  display: inline-flex;\n",
        "                  align-items: center;\n",
        "                  gap: 0.8rem;\n",
        "                  font-size: 1.75rem;\n",
        "                \"\n",
        "              >\n",
        "                <svg\n",
        "                  width=\"0.65em\"\n",
        "                  height=\"0.65em\"\n",
        "                  viewBox=\"0 0 115 115\"\n",
        "                  fill=\"none\"\n",
        "                  xmlns=\"http://www.w3.org/2000/svg\"\n",
        "                >\n",
        "                  <rect width=\"23\" height=\"23\" fill=\"white\"></rect>\n",
        "                  <rect y=\"69\" width=\"23\" height=\"23\" fill=\"white\"></rect>\n",
        "                  <rect x=\"23\" width=\"23\" height=\"23\" fill=\"#AEAEAE\"></rect>\n",
        "                  <rect x=\"23\" y=\"69\" width=\"23\" height=\"23\" fill=\"#AEAEAE\"></rect>\n",
        "                  <rect x=\"46\" width=\"23\" height=\"23\" fill=\"white\"></rect>\n",
        "                  <rect x=\"46\" y=\"69\" width=\"23\" height=\"23\" fill=\"white\"></rect>\n",
        "                  <rect x=\"69\" width=\"23\" height=\"23\" fill=\"black\"></rect>\n",
        "                  <rect x=\"69\" y=\"69\" width=\"23\" height=\"23\" fill=\"black\"></rect>\n",
        "                  <rect x=\"92\" width=\"23\" height=\"23\" fill=\"#D9D9D9\"></rect>\n",
        "                  <rect x=\"92\" y=\"69\" width=\"23\" height=\"23\" fill=\"#AEAEAE\"></rect>\n",
        "                  <rect x=\"115\" y=\"46\" width=\"23\" height=\"23\" fill=\"white\"></rect>\n",
        "                  <rect x=\"115\" y=\"115\" width=\"23\" height=\"23\" fill=\"white\"></rect>\n",
        "                  <rect x=\"115\" y=\"69\" width=\"23\" height=\"23\" fill=\"#D9D9D9\"></rect>\n",
        "                  <rect x=\"92\" y=\"46\" width=\"23\" height=\"23\" fill=\"#AEAEAE\"></rect>\n",
        "                  <rect x=\"92\" y=\"115\" width=\"23\" height=\"23\" fill=\"#AEAEAE\"></rect>\n",
        "                  <rect x=\"92\" y=\"69\" width=\"23\" height=\"23\" fill=\"white\"></rect>\n",
        "                  <rect x=\"69\" y=\"46\" width=\"23\" height=\"23\" fill=\"white\"></rect>\n",
        "                  <rect x=\"69\" y=\"115\" width=\"23\" height=\"23\" fill=\"white\"></rect>\n",
        "                  <rect x=\"69\" y=\"69\" width=\"23\" height=\"23\" fill=\"#D9D9D9\"></rect>\n",
        "                  <rect x=\"46\" y=\"46\" width=\"23\" height=\"23\" fill=\"black\"></rect>\n",
        "                  <rect x=\"46\" y=\"115\" width=\"23\" height=\"23\" fill=\"black\"></rect>\n",
        "                  <rect x=\"46\" y=\"69\" width=\"23\" height=\"23\" fill=\"black\"></rect>\n",
        "                  <rect x=\"23\" y=\"46\" width=\"23\" height=\"23\" fill=\"#D9D9D9\"></rect>\n",
        "                  <rect x=\"23\" y=\"115\" width=\"23\" height=\"23\" fill=\"#AEAEAE\"></rect>\n",
        "                  <rect x=\"23\" y=\"69\" width=\"23\" height=\"23\" fill=\"black\"></rect>\n",
        "                </svg>\n",
        "                <h1 style=\"font-weight: 900; margin-bottom: 7px;\">\n",
        "                  Stable Diffusion Conceptualizer\n",
        "                </h1>\n",
        "              </div>\n",
        "              <p style=\"margin-bottom: 10px; font-size: 94%\">\n",
        "                Navigate through community created concepts and styles via Stable Diffusion Textual Inversion and pick yours for inference.\n",
        "                To train your own concepts and contribute to the library <a style=\"text-decoration: underline\" href=\"https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/sd_textual_inversion_training.ipynb\">check out this notebook</a>.\n",
        "              </p>\n",
        "            </div>\n",
        "  \"\"\"\n",
        "    )\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\n",
        "                \"\"\"\n",
        "          ### Textual-Inversion trained [concepts library](https://huggingface.co/sd-concepts-library) navigator\n",
        "          \"\"\"\n",
        "            )\n",
        "            with gr.Row(elem_id=\"main_row\"):\n",
        "                image_blocks = []\n",
        "                for i, model in enumerate(models):\n",
        "                    with gr.Box().style(border=None):\n",
        "                        title_block(model[\"token\"], model[\"id\"])\n",
        "                        image_blocks.append(\n",
        "                            image_block(model[\"images\"], model[\"concept_type\"])\n",
        "                        )\n",
        "        with gr.Box():\n",
        "            with gr.Row(elem_id=\"prompt_area\").style(\n",
        "                mobile_collapse=False, equal_height=True\n",
        "            ):\n",
        "                text = gr.Textbox(\n",
        "                    label=\"Enter your prompt\",\n",
        "                    placeholder=\"Enter your prompt\",\n",
        "                    show_label=False,\n",
        "                    max_lines=1,\n",
        "                    elem_id=\"prompt_input\",\n",
        "                ).style(\n",
        "                    border=(True, False, True, True),\n",
        "                    rounded=(True, False, False, True),\n",
        "                    container=False,\n",
        "                )\n",
        "                btn = gr.Button(\"Run\", elem_id=\"run_btn\").style(\n",
        "                    margin=False, rounded=(False, True, True, False)\n",
        "                )\n",
        "            with gr.Row().style():\n",
        "                infer_outputs = gr.Gallery(show_label=False).style(\n",
        "                    grid=[2], height=\"512px\"\n",
        "                )\n",
        "            with gr.Row():\n",
        "                gr.HTML(\n",
        "                    '<p style=\"font-size: 85%;margin-top: .75em\">Prompting may not work as you are used to; <code>objects</code> may need the concept added at the end.</p>'\n",
        "                )\n",
        "            with gr.Row():\n",
        "                gr.Examples(\n",
        "                    examples=examples,\n",
        "                    fn=infer,\n",
        "                    inputs=[text],\n",
        "                    outputs=infer_outputs,\n",
        "                    cache_examples=False,\n",
        "                )\n",
        "    checkbox_states = {}\n",
        "    inputs = [text]\n",
        "    btn.click(infer, inputs=inputs, outputs=infer_outputs)\n",
        "demo.launch(inline=False, debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
